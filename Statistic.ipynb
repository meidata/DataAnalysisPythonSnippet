{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics is, at its core, about counting and measuring.\n",
    "\n",
    "In order to do both effectively, we have to define scales on which we can count.\n",
    "\n",
    "One type of scale is called equal interval.\n",
    "\n",
    "Think of the speed of a car. 5 miles per hour is 5 miles per hour, no matter what the current speed is.\n",
    "\n",
    "The difference between 60 and 55 miles per hour will always equal the difference between 10 and 5 miles per hour in real-world terms.\n",
    "\n",
    "Another type of scale is a logarithmic scale.\n",
    "\n",
    "The difference between a 5 and a 6 on the Richter scale is more than the difference between a 4 and 5.\n",
    "\n",
    "This is because each number on the Richter scale means that the earthquake had 10 times the shaking amplitude of the previous number.\n",
    "\n",
    "So, a 6 is 10 times more powerful (technically, powerful is the wrong term, but it makes thinking about this easier) than a 5, which is 10 times more powerful than a 4. A 6 is 100 times more powerful than a 4.\n",
    "\n",
    "We can calculate the mean of values on an equal interval scale by adding up all the values and dividing by the number of values.\n",
    "\n",
    "We could do the same for values on a non-equal interval scale, but the results wouldn't be meaningful, because of the differences between units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Scales\n",
    "So far, we've looked at equal interval and discrete scales, where all of the values are numbers.\n",
    "\n",
    "But, we can also have ordinal scales, where items are ordered by rank.\n",
    "\n",
    "For example, we could ask people how many cigarettes they smoke per day, and the answers could be \"none\", \"a few\", \"some\", \"a lot\".\n",
    "\n",
    "These answers don't map exactly to numbers of cigarettes, but we know that \"a few\" is more than \"none\".\n",
    "\n",
    "This is an ordinal rating scale, and we can assign numbers to the answers, in order, to make them easier to work with.\n",
    "\n",
    "We could map 0 to \"none\", 1 to \"a few\", 2 to \"some\", and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skew\n",
    "Now that we know how to make histograms, notice how the plots have a \"shape\" to them?\n",
    "\n",
    "These shapes are important, and can show you distributional parameters of the data.\n",
    "\n",
    "The first parameter we'll look at is called skew.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "positive_skew = skew(test_scores_positive)\n",
    "negative_skew = skew(test_scores_negative)\n",
    "no_skew = skew(test_scores_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurtosis\n",
    "Another parameter of a distribution is called kurtosis.\n",
    "\n",
    "Kurtosis measures whether the distribution is short and flat, or tall and skinny.\n",
    "\n",
    "\"Shorter\" distributions have a lower maximum frequency, but higher subsequent frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "kurt_platy = kurtosis(test_scores_platy)\n",
    "kurt_lepto = kurtosis(test_scores_lepto)\n",
    "kurt_meso = kurtosis(test_scores_meso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modality\n",
    "Modality is another parameter of distributions.\n",
    "\n",
    "Modality refers to the number of modes, or peaks, in a distribution.\n",
    "\n",
    "Real-world data often is unimodal (only has one mode).\n",
    "\n",
    "\n",
    "This plot has one mode, making it unimodal\n",
    "plt.hist(test_scores_uni)\n",
    "plt.show()\n",
    "\n",
    "This plot has two peaks, and is bimodal\n",
    "#### This could happen if one group of students learned the material, and one learned something else, for example.\n",
    "plt.hist(test_scores_bi)\n",
    "plt.show()\n",
    "\n",
    "#### More than one peak means that the plot is multimodal\n",
    "#### We can't easily measure the modality of a plot, like we can with kurtosis or skew.\n",
    " Often, the best way to detect multimodality is to observe the plot.\n",
    " #### -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Median\n",
    "Another measure of central tendency is the median.\n",
    "\n",
    "This is the midpoint of an array.\n",
    "\n",
    "You have to sort the array, and then take the value in the middle.\n",
    "\n",
    "If two values are in the middle (if there are an even number of items in the array), then you take the mean of the two middle values.\n",
    "\n",
    "\n",
    "##### difference bwt median and mean\n",
    "The median is less sensitive to very large or very small values (outliers), and is a more realistic center of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variance-- how \"spread out\" the data is around the mean.\n",
    "Let's look at variance in the data.\n",
    "\n",
    "Variance tells us how \"spread out\" the data is around the mean.\n",
    "\n",
    "We looked at kurtosis earlier, which measures the shape of a distribution.\n",
    "\n",
    "Variance directly measures how far from the mean the average element in the data is.\n",
    "\n",
    "We calculate variance by subtracting every value from the mean, squaring the results, and averaging them.\n",
    "\n",
    "Mathemically, this looks like σ2=∑i=1n(xi−x¯)2nσ2=∑i=1n(xi−x¯)2n. σ2σ2 is variance, ∑ni=1∑i=1n means \"the sum from 1 to n\", where n is the number of elements in a vector. The formula does the exact same thing we just described, but is the most common way to show it.\n",
    "\n",
    "The \"pf\" column in the data is the total number of personal fouls each player had called on them in the season -- let's look at its variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# The nba data is loaded into the nba_stats variable.\n",
    "# Find the mean value of the column\n",
    "pf_mean = nba_stats[\"pf\"].mean()\n",
    "# Initialize variance at zero\n",
    "variance = 0\n",
    "# Loop through each item in the \"pf\" column\n",
    "for p in nba_stats[\"pts\"]:\n",
    "    # Calculate the difference between the mean and the value\n",
    "    difference = p - pf_mean\n",
    "    # Square the difference -- this ensures that the result isn't negative\n",
    "    # If we didn't square the difference, the total variance would be zero\n",
    "    # ** in python means \"raise whatever comes before this to the power of whatever number is after this\"\n",
    "    square_difference = difference ** 2\n",
    "    # Add the difference to the total\n",
    "    variance += square_difference\n",
    "# Average the total to find the final variance.\n",
    "variance = variance / len(nba_stats[\"pts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### Standard Deviation -->measure how spread out data is.\n",
    "A commonly used way to refer to how far data points are from the mean is called standard deviation.\n",
    "\n",
    "It is typical to measure what percentage of the data is within 1 standard deviation of the mean, or two standard deviations of the mean.\n",
    "\n",
    "Standard deviation is a very useful concept, and is a great way to measure how spread out data is.\n",
    "\n",
    "Luckily for us, standard deviation is just the square root of the variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Correlation\n",
    "One thing that can help us a lot when we need to analyze a lot of variables is to measure correlation -- this means that we don't need to eyeball everything.\n",
    "\n",
    "The most common way to measure correlation is to use Pearson's r, also called an r-value.\n",
    "\n",
    "We'll go through how the calculations work, but for now, we'll focus on the values.\n",
    "\n",
    "An r-value ranges from -1 to 1, and indicates how strongly two variables are correlated.\n",
    "\n",
    "A 1 means perfect positive correlation -- this would show as a straight, upward-sloping line on our plots.\n",
    "\n",
    "A 0 means no correlation -- you'll see a scatterplot with points placed randomly.\n",
    "\n",
    "A -1 means perfect negative correlation -- this would show as a straight, downward-sloping line.\n",
    "\n",
    "Anything between -1 and 0, and 0 and 1 will show up as a scattering of points. The closer the value is to 0, the more random the points will look. The closer to -1 or 1, the more like a line the points will look.\n",
    "\n",
    "We can use a function from scipy to calculate Pearson's r for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# The pearsonr function will find the correlation between two columns of data.\n",
    "# It returns the r value and the p value.  We'll learn more about p values later on.\n",
    "r, p_value = pearsonr(nba_stats[\"fga\"], nba_stats[\"pts\"])\n",
    "# As we can see, this is a very high positive r value -- close to 1\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Covariance\n",
    "We looked at calculating the correlation coefficient with a function, but let's briefly look under the hood to see how we can do it ourselves.\n",
    "\n",
    "Another way to think of correlation is in terms of variance.\n",
    "\n",
    "Two variables are correlated when they both individually vary in similar ways.\n",
    "\n",
    "For example, correlation occurs when if one variable goes up, another variable also goes up.\n",
    "\n",
    "This is called covariance. Covariance is how things vary together.\n",
    "\n",
    "There is a maximum amount of how much two variables can co-vary.\n",
    "\n",
    "This is because of how each variable is individually distributed. Each individual distribution has its own variance. These variances set a maximum theoretical limit on covariance between two variables -- you can't co-vary more from the mean than the two variables individually vary from the mean.\n",
    "\n",
    "The r-value is a ratio between the actual covariance, and the maximum possible positive covariance.\n",
    "\n",
    "The maximum possible covariance occurs when two variables vary perfectly (ie, you see a straight line on the plot).\n",
    "\n",
    "Let's look at actual covariance first. Mathematically speaking, covariance between two variables looks like this: cov(x,y)=∑ni=1(xi−x¯)(yi−y¯)ncov(x,y)=∑i=1n(xi−x¯)(yi−y¯)n. For each element in the vectors x and y, you take the value at each position from 1 to the length of the vectors. Subtract the mean of the vector from that value. Then multiply them together at each position, and all of the resulting values together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### correlation coefficient\n",
    "Now that we know how to calculate covariance, we can calculate the correlation coefficient using the following formula:\n",
    "\n",
    "cov(x,y)σxσycov(x,y)σxσy.\n",
    "\n",
    "For the denominator, we need to multiple the standard deviations for x and y. This is the maximum possible positive covariance -- it's just both the standard deviation values multiplied. If we divide our actual covariance by this, we get the r-value.\n",
    "\n",
    "You can use the std method on any Pandas Dataframe or Series to calculate the standard deviation. The following code returns the standard deviation for the pf column:\n",
    "\n",
    "\n",
    "nba_stats[\"pf\"].std()\n",
    "You can use the cov function from NumPy to compute covariance, returning a 2x2 matrix. The following code returns the covariance between the pf and stl columns:\n",
    "\n",
    "\n",
    "cov(nba_stats[\"pf\"], nba_stats[\"stl\"])[0,1]\n",
    "cov(nba_stats[\"pf\"], nba_stats[\"stl\"])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import cov\n",
    "# The nba_stats variable has already been loaded.\n",
    "r_fta_blk = cov(nba_stats[\"fta\"], nba_stats[\"blk\"])[0,1] /((nba_stats[\"fta\"].var() * nba_stats[\"blk\"].var())** (1/2)) \n",
    "r_ast_stl = cov(nba_stats[\"ast\"], nba_stats[\"stl\"])[0,1]/ ((nba_stats[\"ast\"].var() *nba_stats[\"stl\"].var())** (1/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
